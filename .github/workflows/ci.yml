# .github/workflows/ci.yml
name: Pine Mastery CI

on:
  push:
    paths:
      - 'spec_ingest.py'
      - 'tests/**'
      - 'community_sources.txt'
      - 'harvest_scripts.py'
      - 'generate_finetune_data.py'
      - 'fine_tune.py'
      - '.github/workflows/**'
  workflow_dispatch:

jobs:
  pipeline:
    runs-on: ubuntu-latest
    steps:
      # 1) Check out the repo
      - uses: actions/checkout@v3

      # 2) Set up Python 3.x
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      # 3) Install scraping & parsing deps
      - name: Install requests & BeautifulSoup
        run: pip install requests beautifulsoup4

      # 4) Ingest the latest Pine v6 spec
      - name: Ingest Pine v6 spec
        run: python spec_ingest.py

      # 5) Diff against the previous snapshot
      - name: Diff previous and current spec
        run: |
          python - << 'EOF'
          import os, sys, difflib
          SPEC_DIR = "specs"
          files = sorted(f for f in os.listdir(SPEC_DIR)
                         if f.startswith("pine_v6_spec_") and f.endswith(".html"))
          if len(files) < 2: sys.exit(0)
          old = open(f"{SPEC_DIR}/{files[-2]}", encoding="utf-8").read().splitlines()
          new = open(f"{SPEC_DIR}/{files[-1]}", encoding="utf-8").read().splitlines()
          diff = list(difflib.unified_diff(old, new,
                                           fromfile=files[-2], tofile=files[-1], lineterm=""))
          if diff:
              print("ðŸ“˜ Spec changed:")
              print("\n".join(diff))
              sys.exit(1)
          EOF

      # 6) Generate PineScript tests from the spec
      - name: Generate Pine tests
        run: python tests/generate_tests.py

      # 7) Harvest community scripts
      - name: Harvest community scripts
        run: python harvest_scripts.py

      # 8) Build the fine-tune dataset
      - name: Generate fineâ€‘tune dataset
        run: python generate_finetune_data.py

      # 9) Preview the first few lines to verify format
      - name: Preview fineâ€‘tune dataset format
        run: |
          echo "First 3 lines of finetune_dataset.jsonl:"
          head -n 3 finetune_dataset.jsonl

      # 10) List the dataset file
      - name: List generated dataset file
        run: ls -1 *.jsonl

      # 11) Install OpenAI Python SDK v1.x
      - name: Install OpenAI SDK v1
        run: pip install "openai>=1.0.0"

      # 12) Run the fineâ€‘tune job
      - name: Run fineâ€‘tune
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python fine_tune.py

      # â”€â”€â”€ Upload artifacts for manual download â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Upload fineâ€‘tune dataset
        uses: actions/upload-artifact@v3
        with:
          name: finetune-dataset
          path: finetune_dataset.jsonl

      - name: Upload spec snapshot
        uses: actions/upload-artifact@v3
        with:
          name: pine-spec-html
          path: specs/*.html

      - name: Upload generated tests
        uses: actions/upload-artifact@v3
        with:
          name: pine-tests
          path: tests/*.pine

      - name: Upload community scripts
        uses: actions/upload-artifact@v3
        with:
          name: community-scripts
          path: community/*.pine
